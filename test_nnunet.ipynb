{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 513)\n",
      "Saved flipped image to /home/xulei/projects/wei/2DSAM3D/nnUNet/nnUNetFrame/DATASET/nnUNet_raw/Dataset602_LUNA/labelsTr/IMG_0432.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "# sam mask转换为nnunet的格式，避免数据分布问题\n",
    "'''\n",
    "对齐ground truth和sam出来的mask\n",
    "GT label脊柱向右，和原始图像一致。\n",
    "SAMlabel脊柱在上，并且左右翻转，和原始图像不一致。\n",
    "因此602中训练的mask需要向右转90°并左右翻转，和原始mask一致。\n",
    "以期预测时mask和GT mask一致。\n",
    "'''\n",
    "def flip_slices_90_single_file(p):\n",
    "    filepath=p\n",
    "    img = nib.load(filepath)\n",
    "    data = img.get_fdata()\n",
    "    print(data.shape)\n",
    "    flipped_data = np.rot90(data, 1, axes=(0, 1))\n",
    "            # Flip each slice left-right\n",
    "    flipped_data = np.fliplr(flipped_data)\n",
    "    flipped_img = nib.Nifti1Image(flipped_data, img.affine, img.header)   \n",
    "    # Save the new image to a file\n",
    "    # flipped_filepath = os.path.join(folder, 'flipped_' + filename)\n",
    "    nib.save(flipped_img, filepath)\n",
    "    print('Saved flipped image to', filepath)\n",
    "\n",
    "    \n",
    "def flip_slices_90(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            img = nib.load(filepath)\n",
    "            data = img.get_fdata()\n",
    "            print(data.shape)\n",
    "            # transposed_data = np.transpose(data, (2, 0, 1))\n",
    "            # Flip each slice 180 degrees\n",
    "\n",
    "            # 将输入图像归一化并且右转90°\n",
    "            # flipped_data = np.rot90(data, 1, axes=(1, 2))\n",
    "\n",
    "            # axes可以参考3D_dataset.ipynb中的探索部分, channel在第2维，因此旋转第0维和第1维\n",
    "            flipped_data = np.rot90(data, 1, axes=(0, 1))\n",
    "            # Flip each slice left-right\n",
    "            flipped_data = np.fliplr(flipped_data)\n",
    "            \n",
    "            # Normalize intensity to 0-255\n",
    "            # normalized_data = ((flipped_data - flipped_data.min()) * (255 - 0)) / (flipped_data.max() - flipped_data.min()) + 0\n",
    "            \n",
    "            # Move the channel axis from 0 to 2\n",
    "            # flipped_data = np.transpose(normalized_data, (1, 2, 0))\n",
    "            # print(flipped_data.shape)\n",
    "            \n",
    "            # Create a new NIfTI image with the flipped data\n",
    "            flipped_img = nib.Nifti1Image(flipped_data, img.affine, img.header)\n",
    "            \n",
    "            # Save the new image to a file\n",
    "            # flipped_filepath = os.path.join(folder, 'flipped_' + filename)\n",
    "            nib.save(flipped_img, filepath)\n",
    "            print('Saved flipped image to', filepath)\n",
    "\n",
    "# Replace 'your_folder' with the path to your folder\n",
    "# flip_slices_90(join(nnUNet_raw, 'Dataset602_LUNA/labelsTr/'))\n",
    "flip_slices_90_single_file(join(nnUNet_raw, 'Dataset602_LUNA/labelsTr/IMG_0432.nii.gz'))\n",
    "\n",
    "# flip_slices_180(join(nnUNet_raw, 'Dataset501_LUNA/imagesTs'))\n",
    "# flip_slices_180(join(nnUNet_raw, 'Dataset601_LUNA/imagesTs_predfulres'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "# 将手动标注的数据(4 cases)转换为nnunet的格式（channel的位置和上下颠倒问题），避免模型因为数据分布问题预测不好\n",
    "'''\n",
    "对于形态学方法出来的mask，需要将其转换为nnunet的格式，即channel的位置和上下颠倒问题\n",
    "原始图像脊柱在右边，强度没有归一化（训练时归一化了），预测出来的label是向右转90°并左右翻转的（即脊柱在下）。\n",
    "测试图片强度没有归一化，预测出来的label是完全一样的，没有旋转。\n",
    "因此600测试时，需先将输入图像归一化并且右转90°，脊柱在右，以期分布一致。\n",
    "预测出来的mask向左转180°并左右翻转（向左90左右翻：回归右转90输入图像的mask，再向左90回归原始输入图像，即GT对应图像），以期和GT正常比较。\n",
    "\n",
    "'''\n",
    "def flip_slices_180(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            img = nib.load(filepath)\n",
    "            data = img.get_fdata()\n",
    "            print(data.shape)\n",
    "            # transposed_data = np.transpose(data, (2, 0, 1))\n",
    "            # Flip each slice 180 degrees\n",
    "\n",
    "            # 将输入图像归一化并且右转90°\n",
    "            # flipped_data = np.rot90(data, 1, axes=(1, 2))\n",
    "            flipped_data = np.rot90(data, 2, axes=(0, 1))\n",
    "            # Flip each slice left-right\n",
    "            # flipped_data = np.fliplr(data)\n",
    "            \n",
    "            # Normalize intensity to 0-255\n",
    "            # normalized_data = ((flipped_data - flipped_data.min()) * (255 - 0)) / (flipped_data.max() - flipped_data.min()) + 0\n",
    "            \n",
    "            # Move the channel axis from 0 to 2\n",
    "            # flipped_data = np.transpose(normalized_data, (1, 2, 0))\n",
    "            # print(flipped_data.shape)\n",
    "            \n",
    "            # Create a new NIfTI image with the flipped data\n",
    "            flipped_img = nib.Nifti1Image(flipped_data, img.affine, img.header)\n",
    "            \n",
    "            # Save the new image to a file\n",
    "            # flipped_filepath = os.path.join(folder, 'flipped_' + filename)\n",
    "            nib.save(flipped_img, filepath)\n",
    "            print('Saved flipped image to', filepath)\n",
    "\n",
    "# Replace 'your_folder' with the path to your folder\n",
    "flip_slices_180(join(nnUNet_raw, 'Dataset601_LUNA/imagesTs'))\n",
    "flip_slices_180(join(nnUNet_raw, 'Dataset501_LUNA/imagesTs'))\n",
    "# flip_slices_180(join(nnUNet_raw, 'Dataset601_LUNA/imagesTs_predfulres'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 32 cases that I would like to predict\n",
      "overwrite was set to False, so I am only working on cases that haven't been predicted yet. That's 32 cases.\n",
      "\n",
      "Predicting IMG_0501:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:21<00:17,  2.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     20\u001b[0m predictor\u001b[38;5;241m.\u001b[39minitialize_from_trained_model_folder(\n\u001b[1;32m     21\u001b[0m     join(nnUNet_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset601_LUNA/nnUNetTrainer__nnUNetPlans__3d_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     22\u001b[0m     use_folds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     23\u001b[0m     checkpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_final.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# variant 1: give input and output folders\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnUNet_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataset601_LUNA/Ts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnUNet_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataset601_LUNA/Ts_predfulres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnum_processes_preprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes_segmentation_export\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:251\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_files\u001b[0;34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, save_probabilities, overwrite, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    246\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_get_data_iterator_from_lists_of_filenames(list_of_lists_or_source_folder,\n\u001b[1;32m    247\u001b[0m                                                                          seg_from_prev_stage_files,\n\u001b[1;32m    248\u001b[0m                                                                          output_filename_truncated,\n\u001b[1;32m    249\u001b[0m                                                                          num_processes_preprocessing)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_data_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes_segmentation_export\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:369\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_data_iterator\u001b[0;34m(self, data_iterator, save_probabilities, num_processes_segmentation_export)\u001b[0m\n\u001b[1;32m    366\u001b[0m     sleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    367\u001b[0m     proceed \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m check_workers_alive_and_busy(export_pool, worker_list, r, allowed_num_queued\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_logits_from_preprocessed_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ofile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# this needs to go into background processes\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# export_prediction_from_logits(prediction, properties, configuration_manager, plans_manager,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m#                               dataset_json, ofile, save_probabilities)\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msending off prediction to background worker for resampling and export\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:475\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_logits_from_preprocessed_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# why not leave prediction on device if perform_everything_on_device? Because this may cause the\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# second iteration to crash due to OOM. Grabbing tha twith try except cause way more bloated code than\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# this actually saves computation time\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_sliding_window_return_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_sliding_window_return_logits(data)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:622\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_sliding_window_return_logits\u001b[0;34m(self, input_image)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_everything_on_device \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m# we need to try except here because we can run OOM in which case we need to fall back to CPU as a results device\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         predicted_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_predict_sliding_window_return_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_everything_on_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    626\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction on device was unsuccessful, probably due to a lack of memory. Moving results arrays to CPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:572\u001b[0m, in \u001b[0;36mnnUNetPredictor._internal_predict_sliding_window_return_logits\u001b[0;34m(self, data, slicers, do_on_device)\u001b[0m\n\u001b[1;32m    569\u001b[0m workon \u001b[38;5;241m=\u001b[39m data[sl][\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    570\u001b[0m workon \u001b[38;5;241m=\u001b[39m workon\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 572\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_maybe_mirror_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkon\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(results_device)\n\u001b[1;32m    574\u001b[0m predicted_logits[sl] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (prediction \u001b[38;5;241m*\u001b[39m gaussian \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gaussian \u001b[38;5;28;01melse\u001b[39;00m prediction)\n\u001b[1;32m    575\u001b[0m n_predictions[sl[\u001b[38;5;241m1\u001b[39m:]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (gaussian \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gaussian \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/projects/wei/2dSAM3d_new/nnUNet/nnunetv2/inference/predict_from_raw_data.py:534\u001b[0m, in \u001b[0;36mnnUNetPredictor._internal_maybe_mirror_and_predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    530\u001b[0m     axes_combinations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    531\u001b[0m         c \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mirror_axes)) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcombinations([m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m mirror_axes], i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    532\u001b[0m     ]\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axes \u001b[38;5;129;01min\u001b[39;00m axes_combinations:\n\u001b[0;32m--> 534\u001b[0m         prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, (\u001b[38;5;241m*\u001b[39maxes,))\n\u001b[1;32m    535\u001b[0m     prediction \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(axes_combinations) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/dynamic_network_architectures/architectures/unet.py:59\u001b[0m, in \u001b[0;36mPlainConvUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 59\u001b[0m     skips \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(skips)\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/dynamic_network_architectures/building_blocks/plain_conv_encoder.py:86\u001b[0m, in \u001b[0;36mPlainConvEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 86\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_skips:\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:137\u001b[0m, in \u001b[0;36mStackedConvBlocks.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:71\u001b[0m, in \u001b[0;36mConvDropoutNormReLU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/modules/activation.py:774\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_slope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/nnunet_f/lib/python3.10/site-packages/torch/nn/functional.py:1644\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(leaky_relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, negative_slope\u001b[38;5;241m=\u001b[39mnegative_slope, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1644\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1646\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28minput\u001b[39m, negative_slope)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate the nnUNetPredictor\n",
    "predictor = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    # perform_everything_on_gpu=True,\n",
    "    device=torch.device('cuda', 0),\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True\n",
    ")\n",
    "# initializes the network architecture, loads the checkpoint\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "    join(nnUNet_results, 'Dataset601_LUNA/nnUNetTrainer__nnUNetPlans__3d_fullres'),\n",
    "    use_folds=('1'),\n",
    "    checkpoint_name='checkpoint_final.pth',\n",
    ")\n",
    "# variant 1: give input and output folders\n",
    "predictor.predict_from_files(join(nnUNet_raw, 'Dataset601_LUNA/Ts'),\n",
    "                                join(nnUNet_raw, 'Dataset601_LUNA/Ts_predfulres'),\n",
    "                                save_probabilities=False, overwrite=False,\n",
    "                                num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the nnUNetPredictor\n",
    "predictor = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    # perform_everything_on_gpu=True,\n",
    "    device=torch.device('cuda', 0),\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True\n",
    ")\n",
    "# initializes the network architecture, loads the checkpoint\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "    join(nnUNet_results, 'Dataset501_LUNA/nnUNetTrainer__nnUNetPlans__3d_fullres'),\n",
    "    use_folds=('1'),\n",
    "    checkpoint_name='checkpoint_final.pth',\n",
    ")\n",
    "# variant 1: give input and output folders\n",
    "predictor.predict_from_files(join(nnUNet_raw, 'Dataset501_LUNA/Ts'),\n",
    "                                join(nnUNet_raw, 'Dataset501_LUNA/Ts_predfulres'),\n",
    "                                save_probabilities=False, overwrite=False,\n",
    "                                num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测出来的mask向左转180°并左右翻转（向左90左右翻：回归右转90输入图像的mask，再向左90回归原始输入图像，即GT对应图像），以期和GT正常比较。\n",
    "# \n",
    "def left_turn_180_and_fliplr(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            img = nib.load(filepath)\n",
    "            data = img.get_fdata()\n",
    "            print(data.shape)\n",
    "            # transposed_data = np.transpose(data, (2, 0, 1))\n",
    "            # Flip each slice 180 degrees\n",
    "\n",
    "            #mask左转180°\n",
    "            # flipped_data = np.rot90(data, 2, axes=(0, 1))\n",
    "            # Flip each slice left-right\n",
    "            # flipped_data = np.fliplr(flipped_data)\n",
    "            \n",
    "            # Normalize intensity to 0-255\n",
    "            # normalized_data = ((flipped_data - flipped_data.min()) * (255 - 0)) / (flipped_data.max() - flipped_data.min()) + 0\n",
    "            \n",
    "            # Move the channel axis from 0 to 2\n",
    "            flipped_data = np.transpose(data, (0, 2, 1))\n",
    "            print(flipped_data.shape)\n",
    "            \n",
    "            # Create a new NIfTI image with the flipped data\n",
    "            flipped_img = nib.Nifti1Image(flipped_data, img.affine, img.header)\n",
    "            \n",
    "            # Save the new image to a file\n",
    "            # flipped_filepath = os.path.join(folder, 'flipped_' + filename)\n",
    "            nib.save(flipped_img, filepath)\n",
    "            print('Saved flipped image to', filepath)\n",
    "\n",
    "# Replace 'your_folder' with the path to your folder\n",
    "left_turn_180_and_fliplr(join(nnUNet_raw, 'Dataset501_LUNA/imagesTs_predfulres'))\n",
    "left_turn_180_and_fliplr(join(nnUNet_raw, 'Dataset601_LUNA/imagesTs_predfulres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "# 计算三维下各种指标\n",
    "from __future__ import absolute_import, print_function\n",
    "import pandas as pd\n",
    "import GeodisTK\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# pixel accuracy\n",
    "def binary_pa(s, g):\n",
    "    \"\"\"\n",
    "        calculate the pixel accuracy of two N-d volumes.\n",
    "        s: the segmentation volume of numpy array\n",
    "        g: the ground truth volume of numpy array\n",
    "        \"\"\"\n",
    "    pa = ((s == g).sum()) / g.size\n",
    "    return pa\n",
    "\n",
    "\n",
    "# Dice evaluation\n",
    "def binary_dice(s, g):\n",
    "    \"\"\"\n",
    "    calculate the Dice score of two N-d volumes.\n",
    "    s: the segmentation volume of numpy array\n",
    "    g: the ground truth volume of numpy array\n",
    "    \"\"\"\n",
    "    assert (len(s.shape) == len(g.shape))\n",
    "    prod = np.multiply(s, g)\n",
    "    s0 = prod.sum()\n",
    "    dice = (2.0 * s0 + 1e-10) / (s.sum() + g.sum() + 1e-10)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# IOU evaluation\n",
    "def binary_iou(s, g):\n",
    "    assert (len(s.shape) == len(g.shape))\n",
    "    # 两者相乘值为1的部分为交集\n",
    "    intersecion = np.multiply(s, g)\n",
    "    # 两者相加，值大于0的部分为交集\n",
    "    union = np.asarray(s + g > 0, np.float32)\n",
    "    iou = intersecion.sum() / (union.sum() + 1e-10)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# Hausdorff and ASSD evaluation\n",
    "def get_edge_points(img):\n",
    "    \"\"\"\n",
    "    get edge points of a binary segmentation result\n",
    "    \"\"\"\n",
    "    dim = len(img.shape)\n",
    "    if (dim == 2):\n",
    "        strt = ndimage.generate_binary_structure(2, 1)\n",
    "    else:\n",
    "        strt = ndimage.generate_binary_structure(3, 1)  # 三维结构元素，与中心点相距1个像素点的都是邻域\n",
    "    ero = ndimage.binary_erosion(img, strt)\n",
    "    edge = np.asarray(img, np.uint8) - np.asarray(ero, np.uint8)\n",
    "    return edge\n",
    "\n",
    "\n",
    "def binary_hausdorff95(s, g, spacing=None):\n",
    "    \"\"\"\n",
    "    get the hausdorff distance between a binary segmentation and the ground truth\n",
    "    inputs:\n",
    "        s: a 3D or 2D binary image for segmentation\n",
    "        g: a 2D or 2D binary image for ground truth\n",
    "        spacing: a list for image spacing, length should be 3 or 2\n",
    "    \"\"\"\n",
    "    s_edge = get_edge_points(s)\n",
    "    g_edge = get_edge_points(g)\n",
    "    image_dim = len(s.shape)\n",
    "    assert (image_dim == len(g.shape))\n",
    "    if (spacing == None):\n",
    "        spacing = [1.0] * image_dim\n",
    "    else:\n",
    "        assert (image_dim == len(spacing))\n",
    "    img = np.zeros_like(s)\n",
    "    if (image_dim == 2):\n",
    "        s_dis = GeodisTK.geodesic2d_raster_scan(img, s_edge, 0.0, 2)\n",
    "        g_dis = GeodisTK.geodesic2d_raster_scan(img, g_edge, 0.0, 2)\n",
    "    elif (image_dim == 3):\n",
    "        s_dis = GeodisTK.geodesic3d_raster_scan(img, s_edge, spacing, 0.0, 2)\n",
    "        g_dis = GeodisTK.geodesic3d_raster_scan(img, g_edge, spacing, 0.0, 2)\n",
    "\n",
    "    dist_list1 = s_dis[g_edge > 0]\n",
    "    dist_list1 = sorted(dist_list1)\n",
    "    dist1 = dist_list1[int(len(dist_list1) * 0.95)]\n",
    "    dist_list2 = g_dis[s_edge > 0]\n",
    "    dist_list2 = sorted(dist_list2)\n",
    "    dist2 = dist_list2[int(len(dist_list2) * 0.95)]\n",
    "    return max(dist1, dist2)\n",
    "\n",
    "\n",
    "# 平均表面距离\n",
    "def binary_assd(s, g, spacing=None):\n",
    "    \"\"\"\n",
    "    get the average symetric surface distance between a binary segmentation and the ground truth\n",
    "    inputs:\n",
    "        s: a 3D or 2D binary image for segmentation\n",
    "        g: a 2D or 2D binary image for ground truth\n",
    "        spacing: a list for image spacing, length should be 3 or 2\n",
    "    \"\"\"\n",
    "    s_edge = get_edge_points(s)\n",
    "    g_edge = get_edge_points(g)\n",
    "    image_dim = len(s.shape)\n",
    "    assert (image_dim == len(g.shape))\n",
    "    if (spacing == None):\n",
    "        spacing = [1.0] * image_dim\n",
    "    else:\n",
    "        assert (image_dim == len(spacing))\n",
    "    img = np.zeros_like(s)\n",
    "    if (image_dim == 2):\n",
    "        s_dis = GeodisTK.geodesic2d_raster_scan(img, s_edge, 0.0, 2)\n",
    "        g_dis = GeodisTK.geodesic2d_raster_scan(img, g_edge, 0.0, 2)\n",
    "    elif (image_dim == 3):\n",
    "        s_dis = GeodisTK.geodesic3d_raster_scan(img, s_edge, spacing, 0.0, 2)\n",
    "        g_dis = GeodisTK.geodesic3d_raster_scan(img, g_edge, spacing, 0.0, 2)\n",
    "\n",
    "    ns = s_edge.sum()\n",
    "    ng = g_edge.sum()\n",
    "    s_dis_g_edge = s_dis * g_edge\n",
    "    g_dis_s_edge = g_dis * s_edge\n",
    "    assd = (s_dis_g_edge.sum() + g_dis_s_edge.sum()) / (ns + ng)\n",
    "    return assd\n",
    "\n",
    "\n",
    "# relative volume error evaluation\n",
    "def binary_relative_volume_error(s_volume, g_volume):\n",
    "    s_v = float(s_volume.sum())\n",
    "    g_v = float(g_volume.sum())\n",
    "    assert (g_v > 0)\n",
    "    rve = abs(s_v - g_v) / g_v\n",
    "    return rve\n",
    "\n",
    "\n",
    "def compute_class_sens_spec(pred, label):\n",
    "    \"\"\"\n",
    "    Compute sensitivity and specificity for a particular example\n",
    "    for a given class for binary.\n",
    "    Args:\n",
    "        pred (np.array): binary arrary of predictions, shape is\n",
    "                         (height, width, depth).\n",
    "        label (np.array): binary array of labels, shape is\n",
    "                          (height, width, depth).\n",
    "    Returns:\n",
    "        sensitivity (float): precision for given class_num.\n",
    "        specificity (float): recall for given class_num\n",
    "    \"\"\"\n",
    "    tp = np.sum((pred == 1) & (label == 1))\n",
    "    tn = np.sum((pred == 0) & (label == 0))\n",
    "    fp = np.sum((pred == 1) & (label == 0))\n",
    "    fn = np.sum((pred == 0) & (label == 1))\n",
    "     # 添加错误检查以防止除以零\n",
    "    if tp + fn != 0:\n",
    "        sensitivity = tp / (tp + fn)\n",
    "    else:\n",
    "        sensitivity = 0\n",
    "\n",
    "    if tn + fp != 0:\n",
    "        specificity = tn / (tn + fp)\n",
    "    else:\n",
    "        specificity = 0\n",
    "    # sensitivity = tp / (tp + fn)\n",
    "    # specificity = tn / (tn + fp)\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "\n",
    "def get_evaluation_score(s_volume, g_volume, spacing, metric):\n",
    "    s_volume = (s_volume > 0).astype(np.uint8)\n",
    "    g_volume = (g_volume > 0).astype(np.uint8)\n",
    "    if (len(s_volume.shape) == 4):\n",
    "        assert (s_volume.shape[0] == 1 and g_volume.shape[0] == 1)\n",
    "        s_volume = np.reshape(s_volume, s_volume.shape[1:])\n",
    "        g_volume = np.reshape(g_volume, g_volume.shape[1:])\n",
    "    if (s_volume.shape[0] == 1):\n",
    "        s_volume = np.reshape(s_volume, s_volume.shape[1:])\n",
    "        g_volume = np.reshape(g_volume, g_volume.shape[1:])\n",
    "    metric_lower = metric.lower()\n",
    "\n",
    "    if (metric_lower == \"dice\"):\n",
    "        score = binary_dice(s_volume, g_volume)\n",
    "\n",
    "    elif (metric_lower == \"iou\"):\n",
    "        score = binary_iou(s_volume, g_volume)\n",
    "\n",
    "    elif (metric_lower == 'assd'):\n",
    "        score = binary_assd(s_volume, g_volume, spacing)\n",
    "\n",
    "    elif (metric_lower == \"hausdorff95\"):\n",
    "        score = binary_hausdorff95(s_volume, g_volume, spacing)\n",
    "\n",
    "    elif (metric_lower == \"rve\"):\n",
    "        score = binary_relative_volume_error(s_volume, g_volume)\n",
    "\n",
    "    elif (metric_lower == \"volume\"):\n",
    "        voxel_size = 1.0\n",
    "        for dim in range(len(spacing)):\n",
    "            voxel_size = voxel_size * spacing[dim]\n",
    "        score = g_volume.sum() * voxel_size\n",
    "    else:\n",
    "        raise ValueError(\"unsupported evaluation metric: {0:}\".format(metric))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# import nibabel as nib\n",
    "# # join(nnUNet_raw, 'Dataset501_LUNA/imagesTs'),\n",
    "# #             join(nnUNet_raw, 'Dataset501_LUNA/imagesTs_predfulres'),\n",
    "# seg_path = join(nnUNet_raw, 'Dataset601_LUNA/imagesTs_predfulres')\n",
    "# gd_path = join(nnUNet_raw, 'Dataset601_LUNA/groundtruthseg')\n",
    "# save_dir = './'\n",
    "# seg = sorted(os.listdir(seg_path))\n",
    "\n",
    "# dices = []\n",
    "# hds = []\n",
    "# rves = []\n",
    "# case_name = []\n",
    "# senss = []\n",
    "# specs = []\n",
    "# for name in seg:\n",
    "#     if not name.startswith('.') and name.endswith('nii.gz'):\n",
    "#         # 加载label and segmentation image\n",
    "#         seg_ = nib.load(os.path.join(seg_path, name))\n",
    "#         seg_arr = seg_.get_fdata().astype('float32')\n",
    "#         gd_ = nib.load(os.path.join(gd_path, name))\n",
    "#         gd_arr = gd_.get_fdata().astype('float32')\n",
    "#         case_name.append(name)\n",
    "\n",
    "#         # 求hausdorff95距离\n",
    "#         hd_score = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='hausdorff95')\n",
    "#         hds.append(hd_score)\n",
    "\n",
    "#         # 求体积相关误差\n",
    "#         rve = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='rve')\n",
    "#         rves.append(rve)\n",
    "\n",
    "#         # 求dice\n",
    "#         dice = get_evaluation_score(seg_.get_fdata(), gd_.get_fdata(), spacing=None, metric='dice')\n",
    "#         dices.append(dice)\n",
    "\n",
    "#         # 敏感度，特异性\n",
    "#         sens, spec = compute_class_sens_spec(seg_.get_fdata(), gd_.get_fdata())\n",
    "#         senss.append(sens)\n",
    "#         specs.append(spec)\n",
    "# # 存入pandas\n",
    "# data = {'dice': dices, 'RVE': rves, 'Sens': senss, 'Spec': specs, 'HD95': hds}\n",
    "# df = pd.DataFrame(data=data, columns=['dice', 'RVE', 'Sens', 'Spec', 'HD95'], index=case_name)\n",
    "# df.to_csv(os.path.join(save_dir, 'metrics1.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import nibabel as nib\n",
    "# import pandas as pd\n",
    "\n",
    "# def calculate_metrics(seg_path, gd_path, save_dir):\n",
    "#     seg = sorted(os.listdir(seg_path))\n",
    "\n",
    "#     dices = []\n",
    "#     hds = []\n",
    "#     rves = []\n",
    "#     case_name = []\n",
    "#     senss = []\n",
    "#     specs = []\n",
    "#     for name in seg:\n",
    "#         if not name.startswith('.') and name.endswith('nii.gz'):\n",
    "#             # 加载label and segmentation image\n",
    "#             seg_ = nib.load(os.path.join(seg_path, name))\n",
    "#             seg_arr = seg_.get_fdata().astype('float32')\n",
    "#             gd_ = nib.load(os.path.join(gd_path, name))\n",
    "#             gd_arr = gd_.get_fdata().astype('float32')\n",
    "#             case_name.append(name)\n",
    "\n",
    "#             # 求hausdorff95距离\n",
    "#             hd_score = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='hausdorff95')\n",
    "#             hds.append(hd_score)\n",
    "\n",
    "#             # 求体积相关误差\n",
    "#             rve = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='rve')\n",
    "#             rves.append(rve)\n",
    "\n",
    "#             # 求dice\n",
    "#             dice = get_evaluation_score(seg_.get_fdata(), gd_.get_fdata(), spacing=None, metric='dice')\n",
    "#             dices.append(dice)\n",
    "\n",
    "#             # 敏感度，特异性\n",
    "#             sens, spec = compute_class_sens_spec(seg_.get_fdata(), gd_.get_fdata())\n",
    "#             senss.append(sens)\n",
    "#             specs.append(spec)\n",
    "#     # 存入pandas\n",
    "#     data = {'dice': dices, 'RVE': rves, 'Sens': senss, 'Spec': specs, 'HD95': hds}\n",
    "#     df = pd.DataFrame(data=data, columns=['dice', 'RVE', 'Sens', 'Spec', 'HD95'], index=case_name)\n",
    "#     df.to_csv(os.path.join(save_dir, 'metrics_911.csv'))\n",
    "# # 使用函数\n",
    "# seg_path = '/home/xulei/projects/wei/2DSAM3D/output_gt/'\n",
    "# gd_path = join(nnUNet_raw, 'Dataset501_LUNA/labelTs')\n",
    "# # seg_path = join(nnUNet_raw, 'Dataset501_LUNA/Ts_predfulres')\n",
    "# # gd_path = join(nnUNet_raw, 'Dataset501_LUNA/labelTs')\n",
    "# save_dir = './output'\n",
    "# calculate_metrics(seg_path, gd_path, save_dir)\n",
    "# # seg_path_1 = join(nnUNet_raw, 'Dataset601_LUNA/Ts_predfulresv')\n",
    "# seg_path_1 = '/home/xulei/projects/wei/2DSAM3D/output_sam/'\n",
    "# gd_path_1 = join(nnUNet_raw, 'Dataset601_LUNA/labelTs')\n",
    "# save_dir = './output1'\n",
    "# calculate_metrics(seg_path, gd_path, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:   0%|          | 0/35 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  80%|████████  | 28/35 [33:49<09:19, 79.91s/image] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "def calculate_metrics(seg_path, gd_path, save_dir):\n",
    "    seg = sorted(os.listdir(seg_path))\n",
    "\n",
    "    dices = []\n",
    "    hds = []\n",
    "    rves = []\n",
    "    case_name = []\n",
    "    senss = []\n",
    "    specs = []\n",
    "    \n",
    "    # 使用 tqdm() 包装你的迭代器，显示进度条\n",
    "    for name in tqdm(seg, desc=\"Calculating Metrics\", unit=\"image\"):\n",
    "        if not name.startswith('.') and name.endswith('nii.gz'):\n",
    "            # 加载label and segmentation image\n",
    "            seg_ = nib.load(os.path.join(seg_path, name))\n",
    "            seg_arr = seg_.get_fdata().astype('uint8')\n",
    "            gd_ = nib.load(os.path.join(gd_path, name))\n",
    "            gd_arr = gd_.get_fdata().astype('uint8')\n",
    "            case_name.append(name)\n",
    "\n",
    "            # 求hausdorff95距离\n",
    "            hd_score = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='hausdorff95')\n",
    "            hds.append(hd_score)\n",
    "\n",
    "            # 求体积相关误差\n",
    "            rve = get_evaluation_score(seg_arr, gd_arr, spacing=None, metric='rve')\n",
    "            rves.append(rve)\n",
    "\n",
    "            # 求dice\n",
    "            dice = get_evaluation_score(seg_.get_fdata(), gd_.get_fdata(), spacing=None, metric='dice')\n",
    "            dices.append(dice)\n",
    "\n",
    "            # 敏感度，特异性\n",
    "            sens, spec = compute_class_sens_spec(seg_.get_fdata(), gd_.get_fdata())\n",
    "            senss.append(sens)\n",
    "            specs.append(spec)\n",
    "    \n",
    "    # 存入pandas\n",
    "    data = {'dice': dices, 'RVE': rves, 'Sens': senss, 'Spec': specs, 'HD95': hds}\n",
    "    df = pd.DataFrame(data=data, columns=['dice', 'RVE', 'Sens', 'Spec', 'HD95'], index=case_name)\n",
    "    df.to_csv(os.path.join(save_dir, 'metrics_911.csv'))\n",
    "\n",
    "# 使用函数\n",
    "seg_path = '/home/xulei/projects/wei/2DSAM3D/output_gt/'\n",
    "gd_path = join(nnUNet_raw, 'Dataset501_LUNA/labelTs')\n",
    "save_dir = './output'\n",
    "calculate_metrics(seg_path, gd_path, save_dir)\n",
    "\n",
    "seg_path_1 = '/home/xulei/projects/wei/2DSAM3D/output_sam/'\n",
    "gd_path_1 = join(nnUNet_raw, 'Dataset601_LUNA/labelTs')\n",
    "save_dir_1 = './output1'\n",
    "calculate_metrics(seg_path_1, gd_path_1, save_dir_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
